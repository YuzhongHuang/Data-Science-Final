{
  "name": "Data-science-final",
  "tagline": "",
  "body": "# Data Science Final Project\r\n\r\n#### Yuzhong Huang, Jay Woo, Wilson Tang\r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-dGUb_5Vr-To/Vyeky1w9lRI/AAAAAAAAAhY/xKM8rUROQWgBrLL3FWDRUWrqB5omWNQewCLcB/s0/brand.png \"brand.png\")\r\n\r\n## Introduction\r\n\r\nOn June 12, 2012, healthcare company Practice Fusion published a Kaggle competition to identify patients with Type 2 Diabetes using their de-identified electronic health record data. The main purpose of this contest is to better understand people’s medical history on a large scale as well as to facilitate the diagnosis process. We took a slightly different approach in that instead of looking at just diabetes, we built a tool that can be used to predict any diagnosis as defined by the user.\r\n\r\n## System Architecture\r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-R7PbzlVeni8/VyemaY9MK_I/AAAAAAAAAho/t43daQ1PC-gxH-ezcWgLwB_F6SFnLpNPwCLcB/s0/system+architecture.png \"system architecture.png\")\r\n\r\nThe whole system takes in the processed dataset (as a CSV) and the diagnosis to be predicted (as a string). The inputs are then fed to the dataset generator to separate the features matrix and target vector so that we can use the features to predict the target for patients. After that, we randomly divide the dataset into a train set, validation set, and test set and transform them into Theano shared variables with our data parser.\r\n\r\nFor prediction, we used two approaches. Our first approach was simply feeding the data into the prediction neural network. Our other approach was to first use a feature-learning system to reduce the dimensionality of our data and then pass it through a prediction neural network. For the second method, used an algorithm called the stacked denoising autoencoder.\r\n\r\nIn the following sections, we will explain each of our steps in getting the whole system up, starting with how we pre-processed our data.\r\n\r\n\r\nWe ended up deciding that 107 subcategories represented the ICD-9 data properly for our network.\r\n\r\n## Data Cleaning and Exploration\r\nOriginally, our data came from an SQL database, and as such, the data was not organized by patient or by any other convenient ordering. Several of the files were labeled “conversion” files, whose sole purpose was to convert from one set of IDs to another. For instance, each unique diagnosis ID can be linked to each patient ID using a conversion file. \r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-euBTzbPd5iw/VyenSYrgyHI/AAAAAAAAAh0/cmhpSt1SfrQjs2GTeaTamLQEs1aVhMqGgCLcB/s0/13162263_10207911907734684_1405172986_n.png \"data.png\")\r\n\r\nEventually, we were able to centralize the data into one file containing each patient’s basic information (height, weight, blood pressure, etc.), diagnoses, and IDs.\r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-tF1PwDzWG48/Vyent1T5w-I/AAAAAAAAAiA/POqm9tpO8AITubTFVlDNoiO3QZ10kwu3gCLcB/s0/13128795_10207911924055092_1163516093_o.png \"example.png\")\r\n\r\nOur next goal was to generate features for each patient so that the data can be fed into our machine learning model. In order to do so, we looked at what are called the ICD-9 codes for each patient’s diagnoses. ICD stands for International Statistical Classification of Diseases and Related Health Problems and is used to group similar diagnoses together. For instance, the ICD-9 codes 390 through 459 refer to diseases of the circulatory system.\r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-lQ-UABtLM1k/Vyen7GnfoNI/AAAAAAAAAiM/3W0zu1n_6xMGCH4xp0pW53mZe3cbdf9EACLcB/s0/icd-9-codes.jpg \"icd-9-codes.jpg\")\r\n\r\nWe converted each ICD-9 code into its respective grouping and ended up with nearly 100 diagnosis groupings, such as “diabetes” and “hypertension.” We then went through each patient, and if he/she had a certain diagnosis, we put a 1 for that feature and 0 otherwise. If a patient were diagnosed with appendicitis, they would have a 1 in their appendicitis column.\r\n\r\nFinally, we looked at how the diagnoses were connected. In the graph below, each node represents a different diagnosis. An edge between two diagnoses means that one or more patients was diagnosed with both conditions at one point. Nodes that are further away from the center are least connected to other nodes, while nodes at the center are very densely connected to most other diagnoses.\r\n\r\n\r\n## Feature Learning Neural Network\r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-aLe_ZPvqpN8/VxkWaV0IsuI/AAAAAAAAAgw/oPE6EU8aet41ltkh9zLWfSrwDCbG1SCbACLcB/s0/autoencoder.png \"autoencoder.png\")\r\n\r\nThe autoencoder is a special kind of neural network that effectively reduces the dimensionality of the input. For example, by reducing 6 features to 4 features and then reconstructing the 6 features from 4 features, the network is forced to combine dimensions that are highly related to each other. In this way, the network could potentially extract some important features out from the raw inputs. \r\n\r\nWe built a single-layer, denoising autoencoder and ran a simple example on it by taking 106 features and outputting 80 learned features. Also, we added 30% noise by setting 30 percent of the input features to be 0. By doing that, the network cannot rely much on each individual features, since some of the features are not reliable. Instead, the network is forced to learn the relationships between features to predict the value of noise by using other values. \r\n\r\nWe trained 100 epochs over our network and compared the reconstructed features with the original ones. The result is quite inspiring: the standard deviation of the 106 reconstructed features is about 0.04. Since all of the input features are normalized and are in range of 0 to 1. With a standard deviation of 0.04, the model is doing a good job reconstructing the 27 features from the 22 learned features. But we still need to test how good are the 22 features in representing the data with our prediction network. \r\n\r\n## Prediction Neural Network\r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-RMYxIditqtI/VxkWfqiDg1I/AAAAAAAAAg4/4sbdHwIk6x8TIuKPd4tc1KQXuN9w4WcnQCLcB/s0/neural_net.jpeg \"neural_net.jpeg\")\r\n\r\nIn order to predict which patients have diabetes, we trained a classic feed-forward neural network model on the medical record data. Each neuron in one layer is attached to everything in the next layer, such that the “activation energy” from an adjacent neuron propagates through the network. The neurons in the hidden layer(s) take in energy from all the preceding neurons, and if it reaches above a certain threshold, the node becomes activated. In the context of our dataset, we put in our features after putting them through the autoencoder. If the patient has diabetes, we would expect to see the output layer have a high value, and many of the hidden layer nodes would probably be activated. Otherwise, the output will be small.\r\n\r\nWe implemented the neural network using Theano’s multilayer perceptron tutorial. We noticed that the model had an incredibly low error rate, even with randomized weights, but this was most likely due to the fact that there weren’t a lot of patients who have diabetes in the dataset (less than 1%). In the future, we are considering predicting for a more prevalent condition like hypertension, which many more the patients in our dataset actually have.\r\n\r\n## Result\r\n\r\nWe tested our algorithm on a variety of diagnoses (hypertension, dorsopathies, and acute respiratory infections) to see how well it performed for different predictors. We found that the model was able to predict patients who had hypertension the best, probably because there was more data available for that specific diagnosis. \r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-_LIII9--YmY/VyjXn6JBTvI/AAAAAAAAAi4/lc6_Nebw0uA2aJTH1nekr2PAo8CRgTyjQCLcB/s0/13148449_10207919145675628_1107966449_o.png \"error_plot.png\")\r\n\r\nIn order to validate our model, we looked at what features the model weighted most heavily for predicting hypertension (high blood pressure). Each of these features all had something to do with blood pressure, so we trusted that our algorithm was working correctly.\r\n\r\n![enter image description here](https://lh3.googleusercontent.com/-5vsNVPK38UI/VyjXuqxnyjI/AAAAAAAAAjA/NqQbcpFrvJgwxwjL_mC_nU4fpDJBANkVgCLcB/s0/13112412_10207911431922789_2118678334_o.png \"weights.png\")\r\n\r\n## Future Work\r\n\r\nIn the future, we hope to improve the performance of our model by incorporating the other features in our dataset, such as what medications each patient received and what providers each patient consulted with. Currently, we are only looking at the diagnoses and the ICD-9 codes, but there may be valuable information that could be extracted from the other files. Additionally, we would also like to investigate different machine learning structures that could potentially work better with the given dataset. Perhaps there are other algorithms that work significantly better for our particular case.",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}